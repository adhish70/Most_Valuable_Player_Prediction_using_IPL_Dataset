{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName('Ops').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/Rutgers/Projects/MDSR/IPL-MSDR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "matches = pd.read_csv(path + '/dataset/original_ipldata/matches.csv')\n",
    "deliveries = pd.read_csv(path + '/dataset/original_ipldata/deliveries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of original data (matches.csv)\n",
    "matches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of original data (deliveries.csv)\n",
    "deliveries.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that are of no use\n",
    "matches = matches.drop(columns = ['umpire1', 'umpire2','umpire3','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filing empty values\n",
    "matches = matches.fillna(value = 'None')\n",
    "deliveries = deliveries.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of cleaned data (matches.csv)\n",
    "matches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of cleaned data (deliveries.csv)\n",
    "deliveries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned data (matches.csv)\n",
    "matches.to_csv(path + '/dataset/clean_data/matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned data (deliveries.csv)\n",
    "deliveries.to_csv(path + '/dataset/clean_data/deliveries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teams playing in the league\n",
    "teams = matches['team1'].unique()\n",
    "print(\"Total number of teams participated so far: \" + str(len(matches['team1'].unique())))\n",
    "print(\"Teams participated so far: \")\n",
    "for i in teams:\n",
    "    print(\"- \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Venues\n",
    "print(\"Number of venues matches were played: \" + str(len(matches['venue'].unique())))\n",
    "for i in matches['venue'].unique():\n",
    "    print(\"- \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities the matches were played\n",
    "print(\"Number of cities matches were played: \" + str(len(matches['city'].unique())))\n",
    "for i in matches['city'].unique():\n",
    "    print(\"- \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of bowlers so far\n",
    "print(\"Total number of bowlers: \" + str(len(deliveries['bowler'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of batsmen so far\n",
    "print(\"Total number of batsmen: \" + str(len(deliveries['batsman'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participating players\n",
    "players = set()\n",
    "for i in range(len(deliveries['match_id'])):\n",
    "    players.add(deliveries['bowler'][i])\n",
    "    players.add(deliveries['batsman'][i])\n",
    "    players.add(deliveries['non_striker'][i])\n",
    "print(\"Total number of player: \" + str(len(players)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = spark.read.csv(path + '/dataset/clean_data/matches.csv',inferSchema=True,header=True)\n",
    "deliveries = spark.read.csv(path + '/dataset/clean_data/deliveries.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of matches per season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('seasons')\n",
    "seasons = spark.sql('''Select distinct(season),count(*) as total_matches from seasons group by season ''') \n",
    "seasons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots()\n",
    "a = sns.barplot(x =\"season\", y=\"total_matches\", data=seasons.toPandas(),palette='viridis')\n",
    "a.set_xlabel('Season')\n",
    "a.set_ylabel('Total Matches')\n",
    "a.set_title('Number of matches in each season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of maches played by each team since season 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('team')\n",
    "team = spark.sql('''Select distinct(team), count(*) as total_matches from (Select team1 as team from team UNION ALL (select team2 as team from team)) group by team ''')\n",
    "team.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (5,5))\n",
    "a = sns.barplot(x =\"total_matches\", y=\"team\", data=team.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Team')\n",
    "a.set_xlabel('Total Matches')\n",
    "a.set_title('Number of matches played by each team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total season in which teams have played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('team_season')\n",
    "team_season = spark.sql('''Select team1 as team, min(season) as first_season, max(season) as last_season, count(distinct(season)) as total_seasons from team_season group by team1 order by total_seasons desc''')\n",
    "team_season.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of matches won by teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('most_win')\n",
    "most_win = spark.sql('''Select distinct(winner) as team, count(*) as total_matches from most_win where winner <>'None' group by winner order by total_matches ''')\n",
    "most_win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (5,5))\n",
    "a = sns.barplot(x =\"total_matches\", y=\"team\", data=most_win.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Team')\n",
    "a.set_xlabel('Total Matches')\n",
    "a.set_title('Number of matches won by each team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total matches won by teams in each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('most_win_by_season')\n",
    "most_win_by_season = spark.sql('''Select season, winner as team, count(*) as total_matches_won from most_win_by_season where winner <> 'None' group by season, winner order by total_matches_won desc''')\n",
    "most_win_by_season.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players with maximum man of the match awards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('man_match')\n",
    "man_match = spark.sql('''Select distinct(player_of_match), count(*) as total_matches from man_match group by player_of_match order by total_matches desc limit 10 ''')\n",
    "man_match.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (5,5))\n",
    "a = sns.barplot(x =\"total_matches\", y=\"player_of_match\", data=man_match.toPandas(), palette='viridis')\n",
    "a.set_xlabel('Total Matches')\n",
    "a.set_ylabel('Player')\n",
    "a.set_title('Number of times player won man of the match')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of matches per Venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('venue')\n",
    "venue = spark.sql('''Select distinct(venue), count(*) as total_matches from venue group by venue''')\n",
    "venue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (10,20))\n",
    "a = sns.barplot(x =\"total_matches\", y=\"venue\", data=venue.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Venue')\n",
    "a.set_xlabel('Total Matches')\n",
    "a.set_title('Number of matches at each venue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage toss decisions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('toss')\n",
    "toss = spark.sql('''Select distinct(toss_decision), ((count(toss_decision)*100)/ (select count(*) from toss)) as percentage_count from toss group by toss_decision''')\n",
    "toss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (5,5))\n",
    "a = sns.barplot(x =\"toss_decision\", y=\"percentage_count\", data=toss.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Percentage')\n",
    "a.set_xlabel('Toss Decision')\n",
    "a.set_title('Percentage Plot of toss_decision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of team winning the toss as well as the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('toss_and_won')\n",
    "matches.registerTempTable('toss_won_data')\n",
    "toss_won_data = spark.sql('''Select t1.season, t1.total_matches, \\\n",
    "          t2.count_toss_and_won as count_toss_and_won, \\\n",
    "          (t2.count_toss_and_won / t1.total_matches * 100) as percent_toss_and_won from \\\n",
    "          (Select distinct(season),count(*) as total_matches from seasons group by season)t1 \\\n",
    "          left join (Select distinct(season), count(*) as count_toss_and_won from toss_and_won where toss_winner = winner group by season)t2 on t1.season = t2.season order by season''')\n",
    "toss_won_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (10,5))\n",
    "a = sns.barplot(x =\"season\", y=\"percent_toss_and_won\", data=toss_won_data.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Percentage')\n",
    "a.set_xlabel('Season')\n",
    "a.set_title('Percentage Plot of Season and Toss_and_won')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage matches won by batting first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_batting_first = spark.sql('''Select t1.season, t1.total_matches, \\\n",
    "          t2.win_batting_first as win_batting_first, \\\n",
    "          (t2.win_batting_first/ t1.total_matches * 100) as percent_win_batting_first from \\\n",
    "          (Select distinct(season),count(*) as total_matches from seasons group by season)t1 \\\n",
    "          left join (Select distinct(season), count(*) as win_batting_first from seasons where win_by_runs > 0  group by season)t2 on t1.season = t2.season order by season ''')\n",
    "win_batting_first.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (10,5))\n",
    "a = sns.barplot(x =\"season\", y=\"percent_win_batting_first\", data=win_batting_first.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Percentage')\n",
    "a.set_xlabel('Season')\n",
    "a.set_title('Percentage Plot of Season and won by batting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage matches won by fielding first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_bowling_first = spark.sql('''Select t1.season, t1.total_matches, \\\n",
    "          t2.win_bowling_first as win_bowling_first, \\\n",
    "          (t2.win_bowling_first/ t1.total_matches * 100) as percent_win_bowling_first from \\\n",
    "          (Select distinct(season),count(*) as total_matches from seasons group by season)t1 \\\n",
    "          left join (Select distinct(season), count(*) as win_bowling_first from seasons where win_by_wickets > 0  group by season)t2 on t1.season = t2.season order by season ''')\n",
    "win_bowling_first.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (10,5))\n",
    "a = sns.barplot(x =\"season\", y=\"percent_win_bowling_first\", data=win_bowling_first.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Percentage')\n",
    "a.set_xlabel('Season')\n",
    "a.set_title('Percentage Plot of Season and won by wickets ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "matches = spark.read.csv(path + '/dataset/clean_data/matches.csv',inferSchema=True,header=True)\n",
    "deliveries = spark.read.csv(path + '/dataset/clean_data/deliveries.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating temporary tables of the data\n",
    "matches.registerTempTable('matches_db')\n",
    "deliveries.registerTempTable('deliveries_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging both the tables\n",
    "merged_db = spark.sql('select m.*,d.* from matches_db as m inner join deliveries_db as d on m.id=d.match_id')\n",
    "merged_db.registerTempTable('analysis_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batting Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmba: no. of batsmen\n",
    "# nm: no. of matches played by a batsman\n",
    "# hha: hard hitting ability\n",
    "# f: finisher\n",
    "# fsa: fast scoring ability\n",
    "# con: consistency\n",
    "# rbw: running between wickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|No_of_Batsman|\n",
      "+-------------+\n",
      "|          516|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of Batsmen\n",
    "nmba = spark.sql('select count(distinct(batsman)) as No_of_Batsman from analysis_db')\n",
    "nmba.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Matches played by a batsmen\n",
    "nm = spark.sql('select batsman, count(distinct(match_id)) as No_of_Matches \\\n",
    "                from analysis_db group by batsman')\n",
    "nm.registerTempTable('no_of_matches_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Hitting Ability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Hitting Ability = (4*Fours + 6*Sixes)/Balls Played by Batsman\n",
    "hha = spark.sql('select nmt.batsman as Batsman, round(nvl(t4.hard_hitting_ability,0), 5) as \\\n",
    "                Hard_Hitting_Ability from \\\n",
    "                (select t1.batsman, (t1.fours*4 + t2.sixes*6)/t3.balls_played as hard_hitting_ability\\\n",
    "                from (select batsman,count(*) as fours from analysis_db where batsman_runs = 4 group by batsman) t1 \\\n",
    "                inner join  \\\n",
    "                (select batsman,count(*) as sixes from analysis_db where batsman_runs = 6 \\\n",
    "                group by batsman) t2 on t1.batsman=t2.batsman\\\n",
    "                inner join\\\n",
    "                (select batsman,count(*) as balls_played from analysis_db \\\n",
    "                group by batsman) t3 on t3.batsman=t1.batsman) t4 \\\n",
    "                right join \\\n",
    "                no_of_matches_table nmt on t4.batsman = nmt.batsman')\n",
    "hha.registerTempTable('hard_hitting_ability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+\n",
      "|Rank|      Batsman|Hard_Hitting_Ability|\n",
      "+----+-------------+--------------------+\n",
      "|   1|   AD Russell|             1.37733|\n",
      "|   2|    SP Narine|             1.33056|\n",
      "|   3|        M Ali|             1.21311|\n",
      "|   4|    KK Cooper|                 1.2|\n",
      "|   5|  BCJ Cutting|             1.19178|\n",
      "|   6|    K Gowtham|             1.16279|\n",
      "|   7|CR Brathwaite|             1.13333|\n",
      "|   8|     CH Gayle|             1.10699|\n",
      "|   9|  Rashid Khan|             1.10448|\n",
      "|  10|   GJ Maxwell|             1.09313|\n",
      "+----+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hha = spark.sql('select rank() over (order by Hard_Hitting_Ability desc) as Rank, t1.* \\\n",
    "                  from hard_hitting_ability t1 \\\n",
    "                  inner join \\\n",
    "                  no_of_matches_table t2\\\n",
    "                  on t1.batsman = t2.batsman where no_of_matches>9')\n",
    "hha.registerTempTable('hard_hitting_ability')\n",
    "hha.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+-------+-------+\n",
      "|Rank|      Batsman|Hard_Hitting_Ability| Points|Weights|\n",
      "+----+-------------+--------------------+-------+-------+\n",
      "|   1|   AD Russell|             1.37733|0.99583|1.24479|\n",
      "|   2|    SP Narine|             1.33056|0.99167|1.23958|\n",
      "|   3|        M Ali|             1.21311| 0.9875|1.23438|\n",
      "|   4|    KK Cooper|                 1.2|0.98333|1.22917|\n",
      "|   5|  BCJ Cutting|             1.19178|0.97917|1.22396|\n",
      "|   6|    K Gowtham|             1.16279|  0.975|1.21875|\n",
      "|   7|CR Brathwaite|             1.13333|0.97083|1.21354|\n",
      "|   8|     CH Gayle|             1.10699|0.96667|1.20833|\n",
      "|   9|  Rashid Khan|             1.10448| 0.9625|1.20313|\n",
      "|  10|   GJ Maxwell|             1.09313|0.95833|1.19792|\n",
      "+----+-------------+--------------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hha = spark.sql('select t1.*, round((240-rank)/240, 5) as Points, round((240-rank)*1.25/240, 5) as Weights \\\n",
    "                from hard_hitting_ability t1')\n",
    "hha.registerTempTable('hard_hitting_ability')\n",
    "hha.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finisher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finisher = Not Out innings/Total Innings played\n",
    "f = spark.sql('select t3.batsman as Batsman, round(t3.not_out_innings/t4.total_matches_played, 5) as Finisher from\\\n",
    "              (select t1.batsman, t1.matches_played-t2.number_of_times_out as not_out_innings from \\\n",
    "              (select batsman, count(distinct(match_id)) as matches_played from analysis_db group by batsman) t1\\\n",
    "              inner join \\\n",
    "              (select batsman, count(*) as number_of_times_out from analysis_db where player_dismissed = batsman group by batsman) t2\\\n",
    "              on t1.batsman=t2.batsman) t3\\\n",
    "              inner join\\\n",
    "              (select batsman, count(distinct(match_id)) as total_matches_played \\\n",
    "              from analysis_db group by batsman) t4\\\n",
    "              on t3.batsman = t4.batsman')\n",
    "f.registerTempTable('finisher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+--------+\n",
      "|Rank|       Batsman|Finisher|\n",
      "+----+--------------+--------+\n",
      "|   1| Iqbal Abdulla| 0.92308|\n",
      "|   2|      A Kumble| 0.86667|\n",
      "|   3|Sandeep Sharma| 0.78571|\n",
      "|   4|   S Sreesanth|    0.75|\n",
      "|   5|     S Aravind|     0.7|\n",
      "|   5|     JJ Bumrah|     0.7|\n",
      "|   5|      VR Aaron|     0.7|\n",
      "|   8|     YS Chahal| 0.66667|\n",
      "|   8|      I Sharma| 0.66667|\n",
      "|  10|  Bipul Sharma| 0.64706|\n",
      "+----+--------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = spark.sql('select rank() over (order by finisher desc) as Rank, t1.* \\\n",
    "              from finisher t1 \\\n",
    "              inner join \\\n",
    "              no_of_matches_table t2 \\\n",
    "              on t1.batsman = t2.batsman \\\n",
    "              where no_of_matches>9')\n",
    "f.registerTempTable('finisher')\n",
    "f.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+--------+-------+-------+\n",
      "|Rank|       Batsman|Finisher| Points|Weights|\n",
      "+----+--------------+--------+-------+-------+\n",
      "|   1| Iqbal Abdulla| 0.92308|0.99583|1.24479|\n",
      "|   2|      A Kumble| 0.86667|0.99167|1.23958|\n",
      "|   3|Sandeep Sharma| 0.78571| 0.9875|1.23438|\n",
      "|   4|   S Sreesanth|    0.75|0.98333|1.22917|\n",
      "|   5|     S Aravind|     0.7|0.97917|1.22396|\n",
      "|   5|     JJ Bumrah|     0.7|0.97917|1.22396|\n",
      "|   5|      VR Aaron|     0.7|0.97917|1.22396|\n",
      "|   8|     YS Chahal| 0.66667|0.96667|1.20833|\n",
      "|   8|      I Sharma| 0.66667|0.96667|1.20833|\n",
      "|  10|  Bipul Sharma| 0.64706|0.95833|1.19792|\n",
      "+----+--------------+--------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = spark.sql('select t1.*, round((240-rank)/240, 5) as Points, round((240-rank)*1.25/240, 5) as Weights \\\n",
    "              from finisher t1')\n",
    "f.registerTempTable('finisher')\n",
    "f.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Scoring Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast Scoring Ability = Total Runs/Balls Played by Batsman\n",
    "fsa = spark.sql('select batsman as Batsman, round(Total_Runs/balls_played, 5) as Fast_Scoring_Ability \\\n",
    "                  from (select batsman,sum(batsman_runs) as Total_Runs, count(*) as balls_played \\\n",
    "                  from analysis_db group by batsman)')\n",
    "fsa.registerTempTable('fast_scoring_ability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+\n",
      "|Rank|      Batsman|Fast_Scoring_Ability|\n",
      "+----+-------------+--------------------+\n",
      "|   1|   AD Russell|              1.7995|\n",
      "|   2|    K Gowtham|             1.72093|\n",
      "|   3|        M Ali|             1.69945|\n",
      "|   4|    SP Narine|             1.66944|\n",
      "|   5|    KK Cooper|             1.65714|\n",
      "|   6|  BCJ Cutting|             1.64384|\n",
      "|   7|  Rashid Khan|             1.62687|\n",
      "|   8|      RR Pant|             1.62319|\n",
      "|   9|   J Bairstow|             1.59727|\n",
      "|  10|CR Brathwaite|             1.56667|\n",
      "+----+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsa = spark.sql('select rank() over (order by fast_scoring_ability desc) as Rank, t1.* \\\n",
    "                  from fast_scoring_ability t1 \\\n",
    "                  inner join \\\n",
    "                  no_of_matches_table t2 \\\n",
    "                  on t1.batsman = t2.batsman where no_of_matches>9')\n",
    "fsa.registerTempTable('fast_scoring_ability')\n",
    "fsa.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+-------+-------+\n",
      "|Rank|      Batsman|Fast_Scoring_Ability| Points|Weights|\n",
      "+----+-------------+--------------------+-------+-------+\n",
      "|   1|   AD Russell|              1.7995|0.99583|1.24479|\n",
      "|   2|    K Gowtham|             1.72093|0.99167|1.23958|\n",
      "|   3|        M Ali|             1.69945| 0.9875|1.23438|\n",
      "|   4|    SP Narine|             1.66944|0.98333|1.22917|\n",
      "|   5|    KK Cooper|             1.65714|0.97917|1.22396|\n",
      "|   6|  BCJ Cutting|             1.64384|  0.975|1.21875|\n",
      "|   7|  Rashid Khan|             1.62687|0.97083|1.21354|\n",
      "|   8|      RR Pant|             1.62319|0.96667|1.20833|\n",
      "|   9|   J Bairstow|             1.59727| 0.9625|1.20313|\n",
      "|  10|CR Brathwaite|             1.56667|0.95833|1.19792|\n",
      "+----+-------------+--------------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsa = spark.sql('select t1.*, round((240-rank)/240, 5) as Points, round((240-rank)*1.25/240, 5) as Weights \\\n",
    "                from fast_scoring_ability t1')\n",
    "fsa.registerTempTable('fast_scoring_ability')\n",
    "fsa.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency = Total Runs/Number of Times Out\n",
    "con = spark.sql('select t1.batsman as Batsman, round(t1.Total_runs/t2.no_of_times_dismissed, 5) as Consistency \\\n",
    "                from (select batsman,sum(batsman_runs) as Total_runs \\\n",
    "                from analysis_db group by batsman) t1 \\\n",
    "                inner join \\\n",
    "                (select batsman, count(*) as no_of_times_dismissed \\\n",
    "                from analysis_db where player_dismissed is not null \\\n",
    "                group by batsman) t2 on t1.batsman=t2.batsman')\n",
    "con.registerTempTable('consistency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----------+\n",
      "|Rank|      Batsman|Consistency|\n",
      "+----+-------------+-----------+\n",
      "|   1|   AD Russell|     1.7995|\n",
      "|   2|    K Gowtham|    1.72093|\n",
      "|   3|        M Ali|    1.69945|\n",
      "|   4|    SP Narine|    1.66944|\n",
      "|   5|    KK Cooper|    1.65714|\n",
      "|   6|  BCJ Cutting|    1.64384|\n",
      "|   7|  Rashid Khan|    1.62687|\n",
      "|   8|      RR Pant|    1.62319|\n",
      "|   9|   J Bairstow|    1.59727|\n",
      "|  10|CR Brathwaite|    1.56667|\n",
      "+----+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con = spark.sql('select rank() over (order by consistency desc) as Rank, t1.* \\\n",
    "                  from consistency t1 \\\n",
    "                  inner join \\\n",
    "                  no_of_matches_table t2 \\\n",
    "                  on t1.batsman = t2.batsman where no_of_matches>9')\n",
    "con.registerTempTable('consistency')\n",
    "con.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----------+-------+-------+\n",
      "|Rank|      Batsman|Consistency| Points|Weights|\n",
      "+----+-------------+-----------+-------+-------+\n",
      "|   1|   AD Russell|     1.7995|0.99583|0.99583|\n",
      "|   2|    K Gowtham|    1.72093|0.99167|0.99167|\n",
      "|   3|        M Ali|    1.69945| 0.9875| 0.9875|\n",
      "|   4|    SP Narine|    1.66944|0.98333|0.98333|\n",
      "|   5|    KK Cooper|    1.65714|0.97917|0.97917|\n",
      "|   6|  BCJ Cutting|    1.64384|  0.975|  0.975|\n",
      "|   7|  Rashid Khan|    1.62687|0.97083|0.97083|\n",
      "|   8|      RR Pant|    1.62319|0.96667|0.96667|\n",
      "|   9|   J Bairstow|    1.59727| 0.9625| 0.9625|\n",
      "|  10|CR Brathwaite|    1.56667|0.95833|0.95833|\n",
      "+----+-------------+-----------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con = spark.sql('select t1.*, round((240-rank)/240, 5) as Points, round((240-rank)/240, 5) as Weights \\\n",
    "                from consistency t1')\n",
    "con.registerTempTable('consistency')\n",
    "con.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Running Between Wickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Between Wickets = (Total Runs – (4*Fours + 6*Sixes))/(Total Balls Played – Boundary Balls)\n",
    "rbw = spark.sql('select t9.batsman as Batsman, round(nvl(t8.running_between_wickets,0), 5) as Running_Between_Wickets \\\n",
    "                from (select t4.batsman, t4.first_bracket/t7.second_bracket as Running_Between_Wickets \\\n",
    "                from (select t1.batsman, t3.total_runs-(t1.fours*4 + t2.sixes*6) as first_bracket \\\n",
    "                from (select batsman,count(*) as fours from analysis_db where batsman_runs = 4 \\\n",
    "                group by batsman) t1 \\\n",
    "                inner join \\\n",
    "                (select batsman,count(*) as sixes from analysis_db where batsman_runs = 6 group by batsman) t2 \\\n",
    "                on t1.batsman=t2.batsman \\\n",
    "                inner join \\\n",
    "                (select batsman,sum(batsman_runs) as total_runs from analysis_db group by batsman) t3 \\\n",
    "                on t3.batsman=t1.batsman) t4 \\\n",
    "                inner join\\\n",
    "                (select t5.batsman, t5.total_balls_played-t6.boundry_balls as second_bracket from \\\n",
    "                (select batsman, count(*) as total_balls_played from analysis_db group by batsman) t5 \\\n",
    "                inner join \\\n",
    "                (select batsman, count(*) as boundry_balls from analysis_db where batsman_runs=4 or batsman_runs=6 group by batsman) t6\\\n",
    "                on t5.batsman=t6.batsman) t7 \\\n",
    "                on t4.batsman=t7.batsman) t8 \\\n",
    "                right join \\\n",
    "                no_of_matches_table t9 \\\n",
    "                on t8.batsman = t9.batsman')\n",
    "rbw.registerTempTable('running_between_wickets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------------------+\n",
      "|Rank|       Batsman|Running_Between_Wickets|\n",
      "+----+--------------+-----------------------+\n",
      "|   1|  Bipul Sharma|                0.85577|\n",
      "|   2|       TM Head|                0.83206|\n",
      "|   3|    WPUJC Vaas|                0.80882|\n",
      "|   4|     V Shankar|                0.79245|\n",
      "|   5|      M Kartik|                0.78218|\n",
      "|   6| Mohammad Nabi|                0.77922|\n",
      "|   7|     BA Stokes|                0.76471|\n",
      "|   8|A Ashish Reddy|                0.76364|\n",
      "|   8|     CH Morris|                0.76364|\n",
      "|  10|        S Gill|                0.76235|\n",
      "+----+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbw = spark.sql('select rank() over (order by running_between_wickets desc) as Rank, t1.* \\\n",
    "                  from running_between_wickets t1 \\\n",
    "                  inner join \\\n",
    "                  no_of_matches_table t2\\\n",
    "                  on t1.batsman = t2.batsman where no_of_matches>9')\n",
    "rbw.registerTempTable('running_between_wickets')\n",
    "rbw.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------------------+-------+-------+\n",
      "|Rank|       Batsman|Running_Between_Wickets| Points|Weights|\n",
      "+----+--------------+-----------------------+-------+-------+\n",
      "|   1|  Bipul Sharma|                0.85577|0.99583|0.99583|\n",
      "|   2|       TM Head|                0.83206|0.99167|0.99167|\n",
      "|   3|    WPUJC Vaas|                0.80882| 0.9875| 0.9875|\n",
      "|   4|     V Shankar|                0.79245|0.98333|0.98333|\n",
      "|   5|      M Kartik|                0.78218|0.97917|0.97917|\n",
      "|   6| Mohammad Nabi|                0.77922|  0.975|  0.975|\n",
      "|   7|     BA Stokes|                0.76471|0.97083|0.97083|\n",
      "|   8|A Ashish Reddy|                0.76364|0.96667|0.96667|\n",
      "|   8|     CH Morris|                0.76364|0.96667|0.96667|\n",
      "|  10|        S Gill|                0.76235|0.95833|0.95833|\n",
      "+----+--------------+-----------------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbw = spark.sql('select t1.*, round((240-rank)/240, 5) as Points, round((240-rank)/240, 5) as Weights \\\n",
    "                from running_between_wickets t1')\n",
    "rbw.registerTempTable('running_between_wickets')\n",
    "rbw.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Name for each Metric\n",
    "# Hard Hitting Ability: hard_hitting_ability\n",
    "# Finisher: finisher\n",
    "# Fast Scoring Ability: fast_scoring_ability\n",
    "# Consistency: consistency\n",
    "# Running Between Wickets: running_between_wickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Total Batting Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------------+\n",
      "|          Batsman|Total_Batting_Weights|\n",
      "+-----------------+---------------------+\n",
      "|        CH Morris|              5.27708|\n",
      "|     Bipul Sharma|              5.21459|\n",
      "|        K Gowtham|              5.03438|\n",
      "|Washington Sundar|              5.02187|\n",
      "|        HH Pandya|              5.00208|\n",
      "|         HV Patel|              4.88541|\n",
      "|      BCJ Cutting|              4.82396|\n",
      "|     Ankit Sharma|              4.80625|\n",
      "|      Rashid Khan|              4.76355|\n",
      "|            M Ali|              4.72709|\n",
      "+-----------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_batting_weight = spark.sql('select hht.Batsman, round((hht.Weights+f.Weights+fsa.Weights+c.Weights+rbw.Weights), 5) as Total_Batting_Weights \\\n",
    "                                 from hard_hitting_ability hht \\\n",
    "                                 inner join finisher f \\\n",
    "                                 on hht.Batsman = f.Batsman \\\n",
    "                                 inner join fast_scoring_ability fsa \\\n",
    "                                 on hht.Batsman = fsa.Batsman \\\n",
    "                                 inner join consistency c \\\n",
    "                                 on hht.Batsman = c.Batsman \\\n",
    "                                 inner join running_between_wickets rbw \\\n",
    "                                 on hht.Batsman = rbw.Batsman \\\n",
    "                                 order by Total_Batting_Weights desc')\n",
    "total_batting_weight.registerTempTable('total_batting_weight')\n",
    "total_batting_weight.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bowling Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmbo: no. of bowlers\n",
    "# nmb: no. of matches played by a bowler\n",
    "# eco: economy\n",
    "# wta: wicket taking ability\n",
    "# cons: consistency\n",
    "# cwta: crucial wicket taking ability\n",
    "# spi: short performance index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|No_of_Bowlers|\n",
      "+-------------+\n",
      "|          405|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of Bowlers\n",
    "nmbo = spark.sql('Select count(distinct(bowler)) as No_of_Bowlers from analysis_db ')\n",
    "nmbo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of matches played by a bowler\n",
    "nmb = spark.sql('select bowler as Bowler, count(distinct(match_id)) as No_of_Matches from analysis_db group by bowler')\n",
    "nmb.registerTempTable('no_of_matches_bowlers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Economy = Runs Scored/(Number of balls bowled by bowler/6)\n",
    "eco = spark.sql('Select bowler as Bowler, round(runs/overs, 5) as Economy \\\n",
    "                from (Select bowler,round(count(*)/6) \\\n",
    "                as overs,sum(total_runs) as runs \\\n",
    "                from analysis_db \\\n",
    "                group by bowler)')\n",
    "eco.registerTempTable('economy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+-------+-------------+\n",
      "|Rank|          Bowler|Economy|No_of_Matches|\n",
      "+----+----------------+-------+-------------+\n",
      "|   1|   Sohail Tanvir|   6.25|           11|\n",
      "|   2|      A Chandila|6.28205|           12|\n",
      "|   3|         J Yadav|6.52632|           12|\n",
      "|   4|      SM Pollock|6.53191|           13|\n",
      "|   5|        A Kumble|6.64024|           42|\n",
      "|   6|      GD McGrath|6.65455|           14|\n",
      "|   7|        DW Steyn|6.66848|           92|\n",
      "|   8|  M Muralitharan|6.68561|           66|\n",
      "|   9|RN ten Doeschate|6.71429|           10|\n",
      "|  10|       RD Chahar|6.71429|           15|\n",
      "+----+----------------+-------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eco = spark.sql('select row_number() over (order by e.Economy asc) as Rank, e.*,n.No_of_Matches \\\n",
    "                from economy e \\\n",
    "                inner join \\\n",
    "                no_of_matches_bowlers n \\\n",
    "                on e.Bowler = n.Bowler where n.No_of_Matches>9')\n",
    "eco.registerTempTable('economy')\n",
    "eco.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+-------+-------------+-------+-------+\n",
      "|Rank|          Bowler|Economy|No_of_Matches| Points| Weight|\n",
      "+----+----------------+-------+-------------+-------+-------+\n",
      "|   1|   Sohail Tanvir|   6.25|           11|0.99528|1.49293|\n",
      "|   2|      A Chandila|6.28205|           12|0.99057|1.48585|\n",
      "|   3|         J Yadav|6.52632|           12|0.98585|1.47877|\n",
      "|   4|      SM Pollock|6.53191|           13|0.98113|1.47170|\n",
      "|   5|        A Kumble|6.64024|           42|0.97642|1.46462|\n",
      "|   6|      GD McGrath|6.65455|           14| 0.9717|1.45755|\n",
      "|   7|        DW Steyn|6.66848|           92|0.96698|1.45047|\n",
      "|   8|  M Muralitharan|6.68561|           66|0.96226|1.44340|\n",
      "|   9|RN ten Doeschate|6.71429|           10|0.95755|1.43632|\n",
      "|  10|       RD Chahar|6.71429|           15|0.95283|1.42925|\n",
      "+----+----------------+-------+-------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eco = spark.sql('select *, round((212 - Rank)/212, 5) as Points, round((212 - Rank)*1.5/212, 5) as Weight from economy')\n",
    "eco.registerTempTable('economy')\n",
    "eco.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wicket Taking Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|        Bowler|Wicket_Taking_Ability|\n",
      "+--------------+---------------------+\n",
      "|         A Roy|                 15.0|\n",
      "| Kuldeep Yadav|             21.48718|\n",
      "|    TM Dilshan|                 55.0|\n",
      "|       J Botha|                28.36|\n",
      "|    KA Pollard|             22.78571|\n",
      "| LA Carseldine|                  7.0|\n",
      "|M Muralitharan|             24.70313|\n",
      "|      DR Smith|             21.42308|\n",
      "|Jaskaran Singh|                 18.5|\n",
      "|    A Flintoff|                 33.0|\n",
      "+--------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wicket Taking Ability = Number of balls bowled/Wickets Taken\n",
    "wta = spark.sql('(Select t1.bowler as Bowler, round(t2.balls/t1.wickets, 5) as Wicket_Taking_Ability from \\\n",
    "                (Select bowler,count(*) as wickets from analysis_db where player_dismissed is not null \\\n",
    "                and (dismissal_kind = \\'bowled\\' or  dismissal_kind = \\'hit wicket\\' \\\n",
    "                or  dismissal_kind = \\'stumped\\' or  dismissal_kind = \\'lbw\\' \\\n",
    "                or  dismissal_kind = \\'caught and bowled\\' or  dismissal_kind = \\'caught\\') \\\n",
    "                group by bowler) t1 \\\n",
    "                inner join \\\n",
    "                (select count(*) as balls,bowler from analysis_db group by bowler)t2 on \\\n",
    "                t1.bowler = t2.bowler)')\n",
    "wta.registerTempTable('wicket_taking_ability')\n",
    "wta.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------------+-------------+\n",
      "|Rank|        Bowler|Wicket_Taking_Ability|No_of_Matches|\n",
      "+----+--------------+---------------------+-------------+\n",
      "|   1|       A Zampa|             11.84211|           11|\n",
      "|   2| Sohail Tanvir|             12.04545|           11|\n",
      "|   3|       K Ahmed|             12.68421|           10|\n",
      "|   4|        N Rana|             13.42857|           12|\n",
      "|   5|      K Rabada|                 14.0|           18|\n",
      "|   6|      BJ Hodge|                 14.0|           20|\n",
      "|   7|  CRD Fernando|             14.64706|           10|\n",
      "|   8|    YA Abdulla|                 14.8|           11|\n",
      "|   9|A Ashish Reddy|                 15.0|           20|\n",
      "|  10|       S Gopal|             15.60526|           30|\n",
      "+----+--------------+---------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wta = spark.sql('select row_number() over (order by w.Wicket_Taking_Ability asc) as Rank, w.*, n.No_of_Matches \\\n",
    "                from wicket_taking_ability w \\\n",
    "                inner join \\\n",
    "                no_of_matches_bowlers n on \\\n",
    "                w.Bowler = n.Bowler where n.No_of_Matches > 9')\n",
    "wta.registerTempTable('wicket_taking_ability')\n",
    "wta.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------------+-------------+-------+-------+\n",
      "|Rank|        Bowler|Wicket_Taking_Ability|No_of_Matches| Points| Weight|\n",
      "+----+--------------+---------------------+-------------+-------+-------+\n",
      "|   1|       A Zampa|             11.84211|           11|0.99528|1.49293|\n",
      "|   2| Sohail Tanvir|             12.04545|           11|0.99057|1.48585|\n",
      "|   3|       K Ahmed|             12.68421|           10|0.98585|1.47877|\n",
      "|   4|        N Rana|             13.42857|           12|0.98113|1.47170|\n",
      "|   5|      K Rabada|                 14.0|           18|0.97642|1.46462|\n",
      "|   6|      BJ Hodge|                 14.0|           20| 0.9717|1.45755|\n",
      "|   7|  CRD Fernando|             14.64706|           10|0.96698|1.45047|\n",
      "|   8|    YA Abdulla|                 14.8|           11|0.96226|1.44340|\n",
      "|   9|A Ashish Reddy|                 15.0|           20|0.95755|1.43632|\n",
      "|  10|       S Gopal|             15.60526|           30|0.95283|1.42925|\n",
      "+----+--------------+---------------------+-------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wta = spark.sql('select *,round((212-Rank)/212, 5) as Points,round(1.5*(212-Rank)/212, 5) as Weight \\\n",
    "                from wicket_taking_ability')\n",
    "wta.registerTempTable('wicket_taking_ability')\n",
    "wta.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|        Bowler|Consistency|\n",
      "+--------------+-----------+\n",
      "|         A Roy|       14.0|\n",
      "| Kuldeep Yadav|   30.07692|\n",
      "|    TM Dilshan|       73.6|\n",
      "|       J Botha|      32.72|\n",
      "|    KA Pollard|     31.875|\n",
      "| LA Carseldine|        6.0|\n",
      "|M Muralitharan|   27.57813|\n",
      "|      DR Smith|   31.73077|\n",
      "|Jaskaran Singh|       29.0|\n",
      "|    A Flintoff|       53.0|\n",
      "+--------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consistency = Runs Conceded/Wickets Taken\n",
    "cons = spark.sql('select t1.bowler as Bowler, round(t1.runs/t2.wickets, 5) as Consistency \\\n",
    "                 from (select sum(total_runs) as runs,bowler from analysis_db group by bowler) t1 \\\n",
    "                 inner join \\\n",
    "                 (Select bowler,count(*) as wickets from analysis_db where player_dismissed is not null \\\n",
    "                 and (dismissal_kind = \\'bowled\\' or  dismissal_kind = \\'hit wicket\\' \\\n",
    "                 or dismissal_kind = \\'stumped\\' or  dismissal_kind = \\'lbw\\' \\\n",
    "                 or dismissal_kind = \\'caught and bowled\\' or  dismissal_kind = \\'caught\\') \\\n",
    "                 group by bowler)t2 on t1.bowler = t2.bowler')\n",
    "cons.registerTempTable('consistency')\n",
    "cons.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------+-------------+\n",
      "|Rank|        Bowler|Consistency|No_of_Matches|\n",
      "+----+--------------+-----------+-------------+\n",
      "|   1| Sohail Tanvir|       12.5|           11|\n",
      "|   2|       A Zampa|   14.78947|           11|\n",
      "|   3|        N Rana|   17.71429|           12|\n",
      "|   4|  CRD Fernando|       18.0|           10|\n",
      "|   5|      BJ Hodge|   18.23529|           20|\n",
      "|   6|       K Ahmed|   18.47368|           10|\n",
      "|   7|AD Mascarenhas|   19.21053|           13|\n",
      "|   8|      K Rabada|   19.32258|           18|\n",
      "|   9|  DE Bollinger|   19.35135|           27|\n",
      "|  10|   MF Maharoof|    19.7037|           20|\n",
      "+----+--------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cons = spark.sql('select row_number() over (order by c.Consistency asc) as Rank, c.*,n.No_of_Matches \\\n",
    "                 from consistency c \\\n",
    "                 inner join \\\n",
    "                 no_of_matches_bowlers n on \\\n",
    "                 c.Bowler = n.Bowler where n.No_of_Matches > 9')\n",
    "cons.registerTempTable('consistency')\n",
    "cons.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------+-------------+-------+-------+\n",
      "|Rank|        Bowler|Consistency|No_of_Matches| Points|Weights|\n",
      "+----+--------------+-----------+-------------+-------+-------+\n",
      "|   1| Sohail Tanvir|       12.5|           11|0.99528|0.99528|\n",
      "|   2|       A Zampa|   14.78947|           11|0.99057|0.99057|\n",
      "|   3|        N Rana|   17.71429|           12|0.98585|0.98585|\n",
      "|   4|  CRD Fernando|       18.0|           10|0.98113|0.98113|\n",
      "|   5|      BJ Hodge|   18.23529|           20|0.97642|0.97642|\n",
      "|   6|       K Ahmed|   18.47368|           10| 0.9717| 0.9717|\n",
      "|   7|AD Mascarenhas|   19.21053|           13|0.96698|0.96698|\n",
      "|   8|      K Rabada|   19.32258|           18|0.96226|0.96226|\n",
      "|   9|  DE Bollinger|   19.35135|           27|0.95755|0.95755|\n",
      "|  10|   MF Maharoof|    19.7037|           20|0.95283|0.95283|\n",
      "+----+--------------+-----------+-------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cons = spark.sql('select *,round((212-Rank)/212, 5) as Points, round((212-Rank)/212, 5) as Weights from consistency')\n",
    "cons.registerTempTable('consistency')\n",
    "cons.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crucial Wicket Taking Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------------+\n",
      "|         Bowler|Crucial_Wicket_Taking_Ablity|\n",
      "+---------------+----------------------------+\n",
      "|       A Joseph|                     0.33333|\n",
      "|  Shoaib Akhtar|                     0.33333|\n",
      "|  Sohail Tanvir|                     0.18182|\n",
      "|     YA Abdulla|                     0.18182|\n",
      "|       Umar Gul|                     0.16667|\n",
      "|         AJ Tye|                     0.15385|\n",
      "|        L Ngidi|                     0.14286|\n",
      "|Karanveer Singh|                     0.11111|\n",
      "|       S Curran|                     0.11111|\n",
      "|       K Rabada|                     0.11111|\n",
      "+---------------+----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crucial Wicket Taking Ability = Number of times Four or Five Wickets Taken/Number of Innings Played\n",
    "cwta = spark.sql('select t2.bowler as Bowler, round(nvl(t1.no_of_4wickets/t2.innings,0), 5) as Crucial_Wicket_Taking_Ablity \\\n",
    "                 from (select bowler,count(*) as no_of_4wickets from (select * from \\\n",
    "                 (select match_id,bowler,count(*) as wickets from analysis_db where player_dismissed \\\n",
    "                 is not null \\\n",
    "                 and (dismissal_kind = \\'bowled\\' or  dismissal_kind = \\'hit wicket\\' \\\n",
    "                 or  dismissal_kind = \\'stumped\\' or  dismissal_kind = \\'lbw\\' \\\n",
    "                 or  dismissal_kind = \\'caught and bowled\\' or  dismissal_kind = \\'caught\\') \\\n",
    "                 group by bowler,match_id ) \\\n",
    "                 where wickets > 3) group by bowler)t1 \\\n",
    "                 right join \\\n",
    "                 (select bowler,count(match_id) as \\\n",
    "                 innings from (select distinct(match_id),bowler from analysis_db) \\\n",
    "                 group by bowler)t2 \\\n",
    "                 on t1.bowler = t2.bowler order by Crucial_Wicket_Taking_Ablity desc')\n",
    "cwta.registerTempTable('crucial_wicket_taking_ablity')\n",
    "cwta.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------------------+-------------+\n",
      "|Rank|       Bowler|Crucial_Wicket_Taking_Ablity|No_of_Matches|\n",
      "+----+-------------+----------------------------+-------------+\n",
      "|   1|Sohail Tanvir|                     0.18182|           11|\n",
      "|   1|   YA Abdulla|                     0.18182|           11|\n",
      "|   3|       AJ Tye|                     0.15385|           26|\n",
      "|   4|     K Rabada|                     0.11111|           18|\n",
      "|   5|     J Theron|                         0.1|           10|\n",
      "|   5|  PC Valthaty|                         0.1|           10|\n",
      "|   5| CRD Fernando|                         0.1|           10|\n",
      "|   8|      A Zampa|                     0.09091|           11|\n",
      "|   8|    CJ Jordan|                     0.09091|           11|\n",
      "|  10|   A Chandila|                     0.08333|           12|\n",
      "+----+-------------+----------------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cwta = spark.sql('select rank() over (order by cw.Crucial_Wicket_Taking_Ablity desc) as Rank, cw.*,n.No_of_Matches \\\n",
    "                 from crucial_wicket_taking_ablity cw \\\n",
    "                 inner join no_of_matches_bowlers n on \\\n",
    "                 cw.Bowler = n.Bowler where n.No_of_Matches > 9')\n",
    "cwta.registerTempTable('crucial_wicket_taking_ablity')\n",
    "cwta.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------------------+-------------+-------+-------+\n",
      "|Rank|       Bowler|Crucial_Wicket_Taking_Ablity|No_of_Matches| Points|Weights|\n",
      "+----+-------------+----------------------------+-------------+-------+-------+\n",
      "|   1|Sohail Tanvir|                     0.18182|           11|0.99528|1.49293|\n",
      "|   1|   YA Abdulla|                     0.18182|           11|0.99528|1.49293|\n",
      "|   3|       AJ Tye|                     0.15385|           26|0.98585|1.47877|\n",
      "|   4|     K Rabada|                     0.11111|           18|0.98113|1.47170|\n",
      "|   5|     J Theron|                         0.1|           10|0.97642|1.46462|\n",
      "|   5|  PC Valthaty|                         0.1|           10|0.97642|1.46462|\n",
      "|   5| CRD Fernando|                         0.1|           10|0.97642|1.46462|\n",
      "|   8|      A Zampa|                     0.09091|           11|0.96226|1.44340|\n",
      "|   8|    CJ Jordan|                     0.09091|           11|0.96226|1.44340|\n",
      "|  10|   A Chandila|                     0.08333|           12|0.95283|1.42925|\n",
      "+----+-------------+----------------------------+-------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cwta = spark.sql('select *,round((212-Rank)/212, 5) as Points, round(1.5*(212-Rank)/212, 5) as Weights \\\n",
    "                 from crucial_wicket_taking_ablity')\n",
    "cwta.registerTempTable('crucial_wicket_taking_ablity')\n",
    "cwta.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Performance Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+\n",
      "|         Bowler|Short_Performance_Index|\n",
      "+---------------+-----------------------+\n",
      "|     SL Malinga|                1.22609|\n",
      "|        B Kumar|                1.05263|\n",
      "|       MM Patel|                1.01667|\n",
      "|         AJ Tye|                    1.0|\n",
      "|       A Mishra|                0.97203|\n",
      "|      SP Narine|                0.91176|\n",
      "|Harbhajan Singh|                0.90968|\n",
      "|       L Balaji|                0.85507|\n",
      "|    JP Faulkner|                0.82456|\n",
      "|       A Kumble|                0.82051|\n",
      "+---------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Short Performance Index = (Wickets Taken – 4* Number of Times Four Wickets Taken – 5* Number of Times Five Wickets Taken)/(Innings Played – Number of Times Four Wickets or Five Wickets Taken)\n",
    "spi = spark.sql('select n.bowler as Bowler, round(nvl(t5.Short_Performance_Index,0), 5) as Short_Performance_Index \\\n",
    "                from (select t1.bowler,(t3.wickets - 4*t1.no_of_4wickets - 5*t2.no_of_4wickets)/ \\\n",
    "                (t4.innings - t1.no_of_4wickets - t2.no_of_4wickets) as Short_Performance_Index \\\n",
    "                from (select bowler,count(*) as no_of_4wickets \\\n",
    "                from (select * from (select match_id,bowler,count(*) as wickets from analysis_db where player_dismissed \\\n",
    "                is not null \\\n",
    "                and (dismissal_kind = \\'bowled\\' or  dismissal_kind = \\'hit wicket\\' \\\n",
    "                or  dismissal_kind = \\'stumped\\' or  dismissal_kind = \\'lbw\\' \\\n",
    "                or  dismissal_kind = \\'caught and bowled\\' or  dismissal_kind = \\'caught\\')\\\n",
    "                group by bowler, match_id ) \\\n",
    "                where wickets = 4) group by bowler) t1 \\\n",
    "                inner join \\\n",
    "                (select bowler,count(*) as no_of_4wickets from (select * from \\\n",
    "                (select match_id,bowler,count(*) as wickets from analysis_db where player_dismissed \\\n",
    "                is not null \\\n",
    "                and (dismissal_kind = \\'bowled\\' or  dismissal_kind = \\'hit wicket\\' \\\n",
    "                or dismissal_kind = \\'stumped\\' or  dismissal_kind = \\'lbw\\' \\\n",
    "                or dismissal_kind = \\'caught and bowled\\' or  dismissal_kind = \\'caught\\')\\\n",
    "                group by bowler,match_id ) \\\n",
    "                where wickets = 5) group by bowler) t2 \\\n",
    "                inner join \\\n",
    "                (select bowler,count(*) as wickets from analysis_db where player_dismissed is not null \\\n",
    "                and (dismissal_kind = \\'bowled\\' or  dismissal_kind = \\'hit wicket\\' \\\n",
    "                or  dismissal_kind = \\'stumped\\' or  dismissal_kind = \\'lbw\\' \\\n",
    "                or  dismissal_kind = \\'caught and bowled\\' or  dismissal_kind = \\'caught\\') \\\n",
    "                group by bowler) t3 \\\n",
    "                inner join \\\n",
    "                (select bowler,count(match_id) as \\\n",
    "                innings from (select distinct(match_id),bowler from analysis_db) group by bowler) t4 \\\n",
    "                on t1.bowler = t2.bowler and t1.bowler = t3.bowler and t1.bowler = t4.bowler) t5 \\\n",
    "                right join \\\n",
    "                no_of_matches_bowlers n on t5.Bowler = n.Bowler order by Short_Performance_Index desc')\n",
    "spi.registerTempTable('short_performance_index')\n",
    "spi.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+-----------------------+-------------+\n",
      "|Rank|         Bowler|Short_Performance_Index|No_of_Matches|\n",
      "+----+---------------+-----------------------+-------------+\n",
      "|   1|     SL Malinga|                1.22609|          122|\n",
      "|   2|        B Kumar|                1.05263|          117|\n",
      "|   3|       MM Patel|                1.01667|           63|\n",
      "|   4|         AJ Tye|                    1.0|           26|\n",
      "|   5|       A Mishra|                0.97203|          147|\n",
      "|   6|      SP Narine|                0.91176|          109|\n",
      "|   7|Harbhajan Singh|                0.90968|          157|\n",
      "|   8|       L Balaji|                0.85507|           73|\n",
      "|   9|    JP Faulkner|                0.82456|           60|\n",
      "|  10|       A Kumble|                0.82051|           42|\n",
      "+----+---------------+-----------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spi = spark.sql('select rank() over (order by sp.Short_Performance_Index desc) as Rank, sp.*, n.No_of_Matches \\\n",
    "                from short_performance_index sp \\\n",
    "                inner join \\\n",
    "                no_of_matches_bowlers n on \\\n",
    "                sp.Bowler = n.Bowler where n.No_of_Matches > 9')\n",
    "spi.registerTempTable('short_performance_index')\n",
    "spi.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+-----------------------+-------------+-------+-------+\n",
      "|Rank|         Bowler|Short_Performance_Index|No_of_Matches| Points|Weights|\n",
      "+----+---------------+-----------------------+-------------+-------+-------+\n",
      "|   1|     SL Malinga|                1.22609|          122|0.99528|0.99528|\n",
      "|   2|        B Kumar|                1.05263|          117|0.99057|0.99057|\n",
      "|   3|       MM Patel|                1.01667|           63|0.98585|0.98585|\n",
      "|   4|         AJ Tye|                    1.0|           26|0.98113|0.98113|\n",
      "|   5|       A Mishra|                0.97203|          147|0.97642|0.97642|\n",
      "|   6|      SP Narine|                0.91176|          109| 0.9717| 0.9717|\n",
      "|   7|Harbhajan Singh|                0.90968|          157|0.96698|0.96698|\n",
      "|   8|       L Balaji|                0.85507|           73|0.96226|0.96226|\n",
      "|   9|    JP Faulkner|                0.82456|           60|0.95755|0.95755|\n",
      "|  10|       A Kumble|                0.82051|           42|0.95283|0.95283|\n",
      "+----+---------------+-----------------------+-------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spi = spark.sql('select *,round((212-Rank)/212, 5) as Points, round((212-Rank)/212, 5) as Weights \\\n",
    "                from short_performance_index')\n",
    "spi.registerTempTable('short_performance_index')\n",
    "spi.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Name for each Metric\n",
    "# Economy: economy\n",
    "# Wicket Taking Ability: wicket_taking_ability\n",
    "# Consistency: consistency\n",
    "# Crucial Wicket Taking Ablity: crucial_wicket_taking_ablity\n",
    "# Short Performance Index: short_performance_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Bowling Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+\n",
      "|         Bowler|Total_Bowling_Weights|\n",
      "+---------------+---------------------+\n",
      "|  Sohail Tanvir|              6.41039|\n",
      "| AD Mascarenhas|              6.06368|\n",
      "|   CRD Fernando|              6.06368|\n",
      "|        A Zampa|               6.0519|\n",
      "|     SL Malinga|              5.93632|\n",
      "|   DE Bollinger|              5.82076|\n",
      "|     A Chandila|              5.76416|\n",
      "|       MA Starc|              5.70991|\n",
      "|      SP Narine|              5.58963|\n",
      "|NM Coulter-Nile|              5.57783|\n",
      "+---------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_bowling_weight = spark.sql('select e.bowler as Bowler, round((e.Weight+wta.Weight+c.Weights+cwta.Weights+spi.Weights), 5) as Total_Bowling_Weights \\\n",
    "                                 from economy e \\\n",
    "                                 inner join wicket_taking_ability wta \\\n",
    "                                 on e.Bowler = wta.Bowler \\\n",
    "                                 inner join consistency c \\\n",
    "                                 on e.Bowler = c.Bowler \\\n",
    "                                 inner join crucial_wicket_taking_ablity cwta \\\n",
    "                                 on e.Bowler = cwta.Bowler \\\n",
    "                                 inner join short_performance_index spi \\\n",
    "                                 on e.Bowler = spi.Bowler \\\n",
    "                                 order by Total_Bowling_Weights desc')\n",
    "total_bowling_weight.registerTempTable('total_bowling_weight')\n",
    "total_bowling_weight.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Weights per Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weight = spark.sql('select player, () as Total_Weight \\\n",
    "                         from ')\n",
    "total_weight.registerTempTable('total_weight')\n",
    "total_weight.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
