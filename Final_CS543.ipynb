{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName('Ops').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/Rutgers/Projects/MDSR/IPL-MSDR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "matches = pd.read_csv(path + '/dataset/original_ipldata/matches.csv')\n",
    "deliveries = pd.read_csv(path + '/dataset/original_ipldata/deliveries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of original data (matches.csv)\n",
    "matches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of original data (deliveries.csv)\n",
    "deliveries.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that are of no use\n",
    "matches = matches.drop(columns = ['umpire1', 'umpire2','umpire3','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filing empty values\n",
    "matches = matches.fillna(value = 'None')\n",
    "deliveries = deliveries.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of cleaned data (matches.csv)\n",
    "matches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of cleaned data (deliveries.csv)\n",
    "deliveries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned data (matches.csv)\n",
    "matches.to_csv(path + '/dataset/clean_data/matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned data (deliveries.csv)\n",
    "deliveries.to_csv(path + '/dataset/clean_data/deliveries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teams playing in the league\n",
    "teams = matches['team1'].unique()\n",
    "print(\"Total number of teams participated so far: \" + str(len(matches['team1'].unique())))\n",
    "print(\"Teams participated so far: \")\n",
    "for i in teams:\n",
    "    print(\"- \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Venues\n",
    "print(\"Number of venues matches were played: \" + str(len(matches['venue'].unique())))\n",
    "for i in matches['venue'].unique():\n",
    "    print(\"- \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities the matches were played\n",
    "print(\"Number of cities matches were played: \" + str(len(matches['city'].unique())))\n",
    "for i in matches['city'].unique():\n",
    "    print(\"- \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of bowlers so far\n",
    "print(\"Total number of bowlers: \" + str(len(deliveries['bowler'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of batsmen so far\n",
    "print(\"Total number of batsmen: \" + str(len(deliveries['batsman'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of participating players\n",
    "players = set()\n",
    "for i in range(len(deliveries['match_id'])):\n",
    "    players.add(deliveries['bowler'][i])\n",
    "    players.add(deliveries['batsman'][i])\n",
    "    players.add(deliveries['non_striker'][i])\n",
    "print(\"Total number of player: \" + str(len(players)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = spark.read.csv(path + '/dataset/clean_data/matches.csv',inferSchema=True,header=True)\n",
    "deliveries = spark.read.csv(path + '/dataset/clean_data/deliveries.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of matches per season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('seasons')\n",
    "seasons = spark.sql('''Select distinct(season),count(*) as total_matches from seasons group by season ''') \n",
    "seasons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots()\n",
    "a = sns.barplot(x =\"season\", y=\"total_matches\", data=seasons.toPandas(),palette='viridis')\n",
    "a.set_xlabel('Season')\n",
    "a.set_ylabel('Total Matches')\n",
    "a.set_title('Number of matches in each season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of maches played by each team since season 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('team')\n",
    "team = spark.sql('''Select distinct(team), count(*) as total_matches from (Select team1 as team from team UNION ALL (select team2 as team from team)) group by team ''')\n",
    "team.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (5,5))\n",
    "a = sns.barplot(x =\"total_matches\", y=\"team\", data=team.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Team')\n",
    "a.set_xlabel('Total Matches')\n",
    "a.set_title('Number of matches played by each team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total season in which teams have played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('team_season')\n",
    "team_season = spark.sql('''Select team1 as team, min(season) as first_season, max(season) as last_season, count(distinct(season)) as total_seasons from team_season group by team1 order by total_seasons desc''')\n",
    "team_season.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of matches won by teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('most_win')\n",
    "most_win = spark.sql('''Select distinct(winner) as team, count(*) as total_matches from most_win where winner <>'None' group by winner order by total_matches ''')\n",
    "most_win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (5,5))\n",
    "a = sns.barplot(x =\"total_matches\", y=\"team\", data=most_win.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Team')\n",
    "a.set_xlabel('Total Matches')\n",
    "a.set_title('Number of matches won by each team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total matches won by teams in each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('most_win_by_season')\n",
    "most_win_by_season = spark.sql('''Select season, winner as team, count(*) as total_matches_won from most_win_by_season where winner <> 'None' group by season, winner order by total_matches_won desc''')\n",
    "most_win_by_season.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players with maximum man of the match awards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('man_match')\n",
    "man_match = spark.sql('''Select distinct(player_of_match), count(*) as total_matches from man_match group by player_of_match order by total_matches desc limit 10 ''')\n",
    "man_match.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (5,5))\n",
    "a = sns.barplot(x =\"total_matches\", y=\"player_of_match\", data=man_match.toPandas(), palette='viridis')\n",
    "a.set_xlabel('Total Matches')\n",
    "a.set_ylabel('Player')\n",
    "a.set_title('Number of times player won man of the match')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of matches per Venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('venue')\n",
    "venue = spark.sql('''Select distinct(venue), count(*) as total_matches from venue group by venue''')\n",
    "venue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (10,20))\n",
    "a = sns.barplot(x =\"total_matches\", y=\"venue\", data=venue.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Venue')\n",
    "a.set_xlabel('Total Matches')\n",
    "a.set_title('Number of matches at each venue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage toss decisions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('toss')\n",
    "toss = spark.sql('''Select distinct(toss_decision), ((count(toss_decision)*100)/ (select count(*) from toss)) as percentage_count from toss group by toss_decision''')\n",
    "toss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (5,5))\n",
    "a = sns.barplot(x =\"toss_decision\", y=\"percentage_count\", data=toss.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Percentage')\n",
    "a.set_xlabel('Toss Decision')\n",
    "a.set_title('Percentage Plot of toss_decision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of team winning the toss as well as the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.registerTempTable('toss_and_won')\n",
    "matches.registerTempTable('toss_won_data')\n",
    "toss_won_data = spark.sql('''Select t1.season, t1.total_matches, \\\n",
    "          t2.count_toss_and_won as count_toss_and_won, \\\n",
    "          (t2.count_toss_and_won / t1.total_matches * 100) as percent_toss_and_won from \\\n",
    "          (Select distinct(season),count(*) as total_matches from seasons group by season)t1 \\\n",
    "          left join (Select distinct(season), count(*) as count_toss_and_won from toss_and_won where toss_winner = winner group by season)t2 on t1.season = t2.season order by season''')\n",
    "toss_won_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (10,5))\n",
    "a = sns.barplot(x =\"season\", y=\"percent_toss_and_won\", data=toss_won_data.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Percentage')\n",
    "a.set_xlabel('Season')\n",
    "a.set_title('Percentage Plot of Season and Toss_and_won')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage matches won by batting first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_batting_first = spark.sql('''Select t1.season, t1.total_matches, \\\n",
    "          t2.win_batting_first as win_batting_first, \\\n",
    "          (t2.win_batting_first/ t1.total_matches * 100) as percent_win_batting_first from \\\n",
    "          (Select distinct(season),count(*) as total_matches from seasons group by season)t1 \\\n",
    "          left join (Select distinct(season), count(*) as win_batting_first from seasons where win_by_runs > 0  group by season)t2 on t1.season = t2.season order by season ''')\n",
    "win_batting_first.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (10,5))\n",
    "a = sns.barplot(x =\"season\", y=\"percent_win_batting_first\", data=win_batting_first.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Percentage')\n",
    "a.set_xlabel('Season')\n",
    "a.set_title('Percentage Plot of Season and won by batting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage matches won by fielding first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_bowling_first = spark.sql('''Select t1.season, t1.total_matches, \\\n",
    "          t2.win_bowling_first as win_bowling_first, \\\n",
    "          (t2.win_bowling_first/ t1.total_matches * 100) as percent_win_bowling_first from \\\n",
    "          (Select distinct(season),count(*) as total_matches from seasons group by season)t1 \\\n",
    "          left join (Select distinct(season), count(*) as win_bowling_first from seasons where win_by_wickets > 0  group by season)t2 on t1.season = t2.season order by season ''')\n",
    "win_bowling_first.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, a = plt.subplots(figsize = (10,5))\n",
    "a = sns.barplot(x =\"season\", y=\"percent_win_bowling_first\", data=win_bowling_first.toPandas(), palette='viridis')\n",
    "a.set_ylabel('Percentage')\n",
    "a.set_xlabel('Season')\n",
    "a.set_title('Percentage Plot of Season and won by wickets ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "matches = spark.read.csv(path + '/dataset/clean_data/matches.csv',inferSchema=True,header=True)\n",
    "deliveries = spark.read.csv(path + '/dataset/clean_data/deliveries.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating temporary tables of the data\n",
    "matches.registerTempTable('matches_db')\n",
    "deliveries.registerTempTable('deliveries_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging both the tables\n",
    "merged_db = spark.sql('select m.*,d.* from matches_db as m inner join deliveries_db as d on m.id=d.match_id')\n",
    "merged_db.registerTempTable('analysis_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batting Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm: no. of matches\n",
    "# hha: hard hitting ability\n",
    "# f: finisher\n",
    "# fsa: fast scoring ability\n",
    "# con: consistency\n",
    "# rbw: running between wickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of matches\n",
    "nm = spark.sql('select batsman, count(distinct(match_id)) as no_of_matches \\\n",
    "                from analysis_db group by batsman')\n",
    "nm.registerTempTable('no_of_matches_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Hitting Ability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Hitting Ability = (4*Fours + 6*Sixes)/Balls Played by Batsman\n",
    "hha = spark.sql('select nmt.batsman as Batsman, nvl(t4.hard_hitting_ability,0) as \\\n",
    "                Hard_Hitting_Ability from \\\n",
    "                (select t1.batsman, (t1.fours*4 + t2.sixes*6)/t3.balls_played as hard_hitting_ability\\\n",
    "                from (select batsman,count(*) as fours from analysis_db where batsman_runs = 4 group by batsman) t1 \\\n",
    "                inner join  \\\n",
    "                (select batsman,count(*) as sixes from analysis_db where batsman_runs = 6 \\\n",
    "                group by batsman) t2 on t1.batsman=t2.batsman\\\n",
    "                inner join\\\n",
    "                (select batsman,count(*) as balls_played from analysis_db \\\n",
    "                group by batsman) t3 on t3.batsman=t1.batsman) t4 \\\n",
    "                right join no_of_matches_table nmt on t4.batsman = nmt.batsman')\n",
    "\n",
    "hha.registerTempTable('hard_hitting_ability_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     516|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = spark.sql('select count(*) from hard_hitting_ability_table')\n",
    "count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+\n",
      "|Rank|      Batsman|Hard_Hitting_Ability|\n",
      "+----+-------------+--------------------+\n",
      "|   1|   AD Russell|    1.37733499377335|\n",
      "|   2|    SP Narine|  1.3305613305613306|\n",
      "|   3|        M Ali|  1.2131147540983607|\n",
      "|   4|    KK Cooper|                 1.2|\n",
      "|   5|  BCJ Cutting|  1.1917808219178083|\n",
      "|   6|    K Gowtham|  1.1627906976744187|\n",
      "|   7|CR Brathwaite|  1.1333333333333333|\n",
      "|   8|     CH Gayle|  1.1069945704247843|\n",
      "|   9|  Rashid Khan|  1.1044776119402986|\n",
      "|  10|   GJ Maxwell|  1.0931263858093125|\n",
      "+----+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hha = spark.sql('select rank() over (order by Hard_Hitting_Ability desc) as Rank, t1.* \\\n",
    "                  from hard_hitting_ability_table t1 \\\n",
    "                  inner join \\\n",
    "                  no_of_matches_table t2\\\n",
    "                  on t1.batsman = t2.batsman where no_of_matches>9')\n",
    "hha.registerTempTable('hard_hitting_ability_rank')\n",
    "hha.show(10)\n",
    "count = spark.sql('select count(*) from hard_hitting_ability_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+------------------+\n",
      "|Rank|      Batsman|Hard_Hitting_Ability|            Points|\n",
      "+----+-------------+--------------------+------------------+\n",
      "|   1|   AD Russell|    1.37733499377335|0.9958333333333333|\n",
      "|   2|    SP Narine|  1.3305613305613306|0.9916666666666667|\n",
      "|   3|        M Ali|  1.2131147540983607|            0.9875|\n",
      "|   4|    KK Cooper|                 1.2|0.9833333333333333|\n",
      "|   5|  BCJ Cutting|  1.1917808219178083|0.9791666666666666|\n",
      "|   6|    K Gowtham|  1.1627906976744187|             0.975|\n",
      "|   7|CR Brathwaite|  1.1333333333333333|0.9708333333333333|\n",
      "|   8|     CH Gayle|  1.1069945704247843|0.9666666666666667|\n",
      "|   9|  Rashid Khan|  1.1044776119402986|            0.9625|\n",
      "|  10|   GJ Maxwell|  1.0931263858093125|0.9583333333333334|\n",
      "+----+-------------+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hha = spark.sql('select t1.*, (240-rank)/240 as Points from hard_hitting_ability_rank t1')\n",
    "hha.registerTempTable('hard_hitting_ability_points')\n",
    "hha.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+------------------+------------------+\n",
      "|Rank|      Batsman|Hard_Hitting_Ability|            Points|            Weight|\n",
      "+----+-------------+--------------------+------------------+------------------+\n",
      "|   1|   AD Russell|    1.37733499377335|0.9958333333333333|1.2447916666666667|\n",
      "|   2|    SP Narine|  1.3305613305613306|0.9916666666666667|1.2395833333333335|\n",
      "|   3|        M Ali|  1.2131147540983607|            0.9875|          1.234375|\n",
      "|   4|    KK Cooper|                 1.2|0.9833333333333333|1.2291666666666665|\n",
      "|   5|  BCJ Cutting|  1.1917808219178083|0.9791666666666666|1.2239583333333333|\n",
      "|   6|    K Gowtham|  1.1627906976744187|             0.975|           1.21875|\n",
      "|   7|CR Brathwaite|  1.1333333333333333|0.9708333333333333|1.2135416666666667|\n",
      "|   8|     CH Gayle|  1.1069945704247843|0.9666666666666667|1.2083333333333333|\n",
      "|   9|  Rashid Khan|  1.1044776119402986|            0.9625|          1.203125|\n",
      "|  10|   GJ Maxwell|  1.0931263858093125|0.9583333333333334|1.1979166666666667|\n",
      "+----+-------------+--------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hha = spark.sql('select t1.*, Points*1.25 as Weight from hard_hitting_ability_points t1')\n",
    "hha.registerTempTable('hard_hitting_ability_weights')\n",
    "hha.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finisher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finisher = Not Out innings/Total Innings played\n",
    "f = spark.sql('select t3.batsman as Batsman, t3.not_out_innings/t4.total_matches_played as Finisher from\\\n",
    "              (select t1.batsman, t1.matches_played-t2.number_of_times_out as not_out_innings from \\\n",
    "              (select batsman, count(distinct(match_id)) as matches_played from analysis_db group by batsman) t1\\\n",
    "              inner join \\\n",
    "              (select batsman, count(*) as number_of_times_out from analysis_db where player_dismissed = batsman group by batsman) t2\\\n",
    "              on t1.batsman=t2.batsman) t3\\\n",
    "              inner join\\\n",
    "              (select batsman, count(distinct(match_id)) as total_matches_played \\\n",
    "              from analysis_db group by batsman) t4\\\n",
    "              on t3.batsman = t4.batsman')\n",
    "f.registerTempTable('finisher_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+------------------+\n",
      "|Rank|       Batsman|          Finisher|\n",
      "+----+--------------+------------------+\n",
      "|   1| Iqbal Abdulla|0.9230769230769231|\n",
      "|   2|      A Kumble|0.8666666666666667|\n",
      "|   3|Sandeep Sharma|0.7857142857142857|\n",
      "|   4|   S Sreesanth|              0.75|\n",
      "|   5|     S Aravind|               0.7|\n",
      "|   5|     JJ Bumrah|               0.7|\n",
      "|   5|      VR Aaron|               0.7|\n",
      "|   8|     YS Chahal|0.6666666666666666|\n",
      "|   8|      I Sharma|0.6666666666666666|\n",
      "|  10|  Bipul Sharma|0.6470588235294118|\n",
      "+----+--------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = spark.sql('select rank() over (order by finisher desc) as Rank, t1.* \\\n",
    "              from finisher_table t1 \\\n",
    "              inner join \\\n",
    "              no_of_matches_table t2\\\n",
    "              on t1.batsman = t2.batsman \\\n",
    "              where no_of_matches>9')\n",
    "f.registerTempTable('finisher_rank')\n",
    "f.show(10)\n",
    "count = spark.sql('select count(*) from finisher_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+------------------+------------------+\n",
      "|Rank|       Batsman|          Finisher|            Points|\n",
      "+----+--------------+------------------+------------------+\n",
      "|   1| Iqbal Abdulla|0.9230769230769231|0.9958333333333333|\n",
      "|   2|      A Kumble|0.8666666666666667|0.9916666666666667|\n",
      "|   3|Sandeep Sharma|0.7857142857142857|            0.9875|\n",
      "|   4|   S Sreesanth|              0.75|0.9833333333333333|\n",
      "|   5|     S Aravind|               0.7|0.9791666666666666|\n",
      "|   5|     JJ Bumrah|               0.7|0.9791666666666666|\n",
      "|   5|      VR Aaron|               0.7|0.9791666666666666|\n",
      "|   8|     YS Chahal|0.6666666666666666|0.9666666666666667|\n",
      "|   8|      I Sharma|0.6666666666666666|0.9666666666666667|\n",
      "|  10|  Bipul Sharma|0.6470588235294118|0.9583333333333334|\n",
      "+----+--------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = spark.sql('select t1.*, (240-rank)/240 as Points from finisher_rank t1')\n",
    "f.registerTempTable('finisher_points')\n",
    "f.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+------------------+------------------+------------------+\n",
      "|Rank|       Batsman|          Finisher|            Points|            Weight|\n",
      "+----+--------------+------------------+------------------+------------------+\n",
      "|   1| Iqbal Abdulla|0.9230769230769231|0.9958333333333333|1.2447916666666667|\n",
      "|   2|      A Kumble|0.8666666666666667|0.9916666666666667|1.2395833333333335|\n",
      "|   3|Sandeep Sharma|0.7857142857142857|            0.9875|          1.234375|\n",
      "|   4|   S Sreesanth|              0.75|0.9833333333333333|1.2291666666666665|\n",
      "|   5|     S Aravind|               0.7|0.9791666666666666|1.2239583333333333|\n",
      "|   5|     JJ Bumrah|               0.7|0.9791666666666666|1.2239583333333333|\n",
      "|   5|      VR Aaron|               0.7|0.9791666666666666|1.2239583333333333|\n",
      "|   8|     YS Chahal|0.6666666666666666|0.9666666666666667|1.2083333333333333|\n",
      "|   8|      I Sharma|0.6666666666666666|0.9666666666666667|1.2083333333333333|\n",
      "|  10|  Bipul Sharma|0.6470588235294118|0.9583333333333334|1.1979166666666667|\n",
      "+----+--------------+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = spark.sql('select *, Points*1.25 as Weight from finisher_points')\n",
    "f.registerTempTable('finisher_weights')\n",
    "f.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Scoring Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast Scoring Ability = Total Runs/Balls Played by Batsman\n",
    "fsa = spark.sql('select batsman as Batsman, Total_Runs/balls_played as Fast_Scoring_Ability \\\n",
    "                  from (select batsman,sum(batsman_runs) as Total_Runs, count(*) as balls_played \\\n",
    "                  from analysis_db group by batsman)')\n",
    "fsa.registerTempTable('fast_scoring_ability_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+\n",
      "|Rank|      Batsman|Fast_Scoring_Ability|\n",
      "+----+-------------+--------------------+\n",
      "|   1|   AD Russell|  1.7995018679950188|\n",
      "|   2|    K Gowtham|  1.7209302325581395|\n",
      "|   3|        M Ali|  1.6994535519125684|\n",
      "|   4|    SP Narine|  1.6694386694386694|\n",
      "|   5|    KK Cooper|  1.6571428571428573|\n",
      "|   6|  BCJ Cutting|   1.643835616438356|\n",
      "|   7|  Rashid Khan|   1.626865671641791|\n",
      "|   8|      RR Pant|  1.6231884057971016|\n",
      "|   9|   J Bairstow|  1.5972696245733788|\n",
      "|  10|CR Brathwaite|  1.5666666666666667|\n",
      "+----+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsa = spark.sql('select rank() over (order by fast_scoring_ability desc) as Rank, t1.* \\\n",
    "                  from fast_scoring_ability_table t1 \\\n",
    "                  inner join \\\n",
    "                  no_of_matches_table t2 \\\n",
    "                  on t1.batsman = t2.batsman where no_of_matches>9')\n",
    "fsa.registerTempTable('fast_scoring_ability_rank')\n",
    "fsa.show(10)\n",
    "count = spark.sql('select count(*) from fast_scoring_ability_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+------------------+\n",
      "|Rank|      Batsman|Fast_Scoring_Ability|            Points|\n",
      "+----+-------------+--------------------+------------------+\n",
      "|   1|   AD Russell|  1.7995018679950188|0.9958333333333333|\n",
      "|   2|    K Gowtham|  1.7209302325581395|0.9916666666666667|\n",
      "|   3|        M Ali|  1.6994535519125684|            0.9875|\n",
      "|   4|    SP Narine|  1.6694386694386694|0.9833333333333333|\n",
      "|   5|    KK Cooper|  1.6571428571428573|0.9791666666666666|\n",
      "|   6|  BCJ Cutting|   1.643835616438356|             0.975|\n",
      "|   7|  Rashid Khan|   1.626865671641791|0.9708333333333333|\n",
      "|   8|      RR Pant|  1.6231884057971016|0.9666666666666667|\n",
      "|   9|   J Bairstow|  1.5972696245733788|            0.9625|\n",
      "|  10|CR Brathwaite|  1.5666666666666667|0.9583333333333334|\n",
      "+----+-------------+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsa = spark.sql('select t1.*, (240-rank)/240 as Points \\\n",
    "                from fast_scoring_ability_rank t1')\n",
    "fsa.registerTempTable('fast_scoring_ability_points')\n",
    "fsa.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+------------------+------------------+\n",
      "|Rank|      Batsman|Fast_Scoring_Ability|            Points|            Weight|\n",
      "+----+-------------+--------------------+------------------+------------------+\n",
      "|   1|   AD Russell|  1.7995018679950188|0.9958333333333333|1.2447916666666667|\n",
      "|   2|    K Gowtham|  1.7209302325581395|0.9916666666666667|1.2395833333333335|\n",
      "|   3|        M Ali|  1.6994535519125684|            0.9875|          1.234375|\n",
      "|   4|    SP Narine|  1.6694386694386694|0.9833333333333333|1.2291666666666665|\n",
      "|   5|    KK Cooper|  1.6571428571428573|0.9791666666666666|1.2239583333333333|\n",
      "|   6|  BCJ Cutting|   1.643835616438356|             0.975|           1.21875|\n",
      "|   7|  Rashid Khan|   1.626865671641791|0.9708333333333333|1.2135416666666667|\n",
      "|   8|      RR Pant|  1.6231884057971016|0.9666666666666667|1.2083333333333333|\n",
      "|   9|   J Bairstow|  1.5972696245733788|            0.9625|          1.203125|\n",
      "|  10|CR Brathwaite|  1.5666666666666667|0.9583333333333334|1.1979166666666667|\n",
      "+----+-------------+--------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fsa = spark.sql('select t1.*, Points*1.25 as Weight from fast_scoring_ability_points t1')\n",
    "fsa.registerTempTable('fast_scoring_ability_weights')\n",
    "fsa.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency = Total Runs/Number of Times Out\n",
    "con = spark.sql('select t1.batsman as Batsman,t1.Total_runs/t2.no_of_times_dismissed as Consistency \\\n",
    "                        from (select batsman,sum(batsman_runs) as Total_runs \\\n",
    "                        from analysis_db group by batsman) t1 \\\n",
    "                        inner join \\\n",
    "                        (select batsman, count(*) as no_of_times_dismissed \\\n",
    "                        from analysis_db where player_dismissed is not null \\\n",
    "                        group by batsman) t2 on t1.batsman=t2.batsman')\n",
    "con.registerTempTable('consistency_table')\n",
    "count = spark.sql('select count(*) from consistency_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------------------+\n",
      "|Rank|      Batsman|       Consistency|\n",
      "+----+-------------+------------------+\n",
      "|   1|   AD Russell|1.7995018679950188|\n",
      "|   2|    K Gowtham|1.7209302325581395|\n",
      "|   3|        M Ali|1.6994535519125684|\n",
      "|   4|    SP Narine|1.6694386694386694|\n",
      "|   5|    KK Cooper|1.6571428571428573|\n",
      "|   6|  BCJ Cutting| 1.643835616438356|\n",
      "|   7|  Rashid Khan| 1.626865671641791|\n",
      "|   8|      RR Pant|1.6231884057971016|\n",
      "|   9|   J Bairstow|1.5972696245733788|\n",
      "|  10|CR Brathwaite|1.5666666666666667|\n",
      "+----+-------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con = spark.sql('select rank() over (order by consistency desc) as Rank, t1.* \\\n",
    "                  from consistency_table t1 \\\n",
    "                  inner join \\\n",
    "                  no_of_matches_table t2 \\\n",
    "                  on t1.batsman = t2.batsman where no_of_matches>9')\n",
    "con.registerTempTable('consistency_rank')\n",
    "con.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------------------+------------------+\n",
      "|Rank|      Batsman|       Consistency|            Points|\n",
      "+----+-------------+------------------+------------------+\n",
      "|   1|   AD Russell|1.7995018679950188|0.9958333333333333|\n",
      "|   2|    K Gowtham|1.7209302325581395|0.9916666666666667|\n",
      "|   3|        M Ali|1.6994535519125684|            0.9875|\n",
      "|   4|    SP Narine|1.6694386694386694|0.9833333333333333|\n",
      "|   5|    KK Cooper|1.6571428571428573|0.9791666666666666|\n",
      "|   6|  BCJ Cutting| 1.643835616438356|             0.975|\n",
      "|   7|  Rashid Khan| 1.626865671641791|0.9708333333333333|\n",
      "|   8|      RR Pant|1.6231884057971016|0.9666666666666667|\n",
      "|   9|   J Bairstow|1.5972696245733788|            0.9625|\n",
      "|  10|CR Brathwaite|1.5666666666666667|0.9583333333333334|\n",
      "+----+-------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con = spark.sql('select t1.*, (240-rank)/240 as Points from consistency_rank t1')\n",
    "con.registerTempTable('consistency_points')\n",
    "con.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------------------+------------------+------------------+\n",
      "|Rank|      Batsman|       Consistency|            Points|            Weight|\n",
      "+----+-------------+------------------+------------------+------------------+\n",
      "|   1|   AD Russell|1.7995018679950188|0.9958333333333333|0.9958333333333333|\n",
      "|   2|    K Gowtham|1.7209302325581395|0.9916666666666667|0.9916666666666667|\n",
      "|   3|        M Ali|1.6994535519125684|            0.9875|            0.9875|\n",
      "|   4|    SP Narine|1.6694386694386694|0.9833333333333333|0.9833333333333333|\n",
      "|   5|    KK Cooper|1.6571428571428573|0.9791666666666666|0.9791666666666666|\n",
      "|   6|  BCJ Cutting| 1.643835616438356|             0.975|             0.975|\n",
      "|   7|  Rashid Khan| 1.626865671641791|0.9708333333333333|0.9708333333333333|\n",
      "|   8|      RR Pant|1.6231884057971016|0.9666666666666667|0.9666666666666667|\n",
      "|   9|   J Bairstow|1.5972696245733788|            0.9625|            0.9625|\n",
      "|  10|CR Brathwaite|1.5666666666666667|0.9583333333333334|0.9583333333333334|\n",
      "+----+-------------+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con = spark.sql('select t1.*, Points as Weight from consistency_points t1')\n",
    "con.registerTempTable('consistency_weights')\n",
    "con.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Running Between Wickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Between Wickets = (Total Runs – (4*Fours + 6*Sixes))/(Total Balls Played – Boundary Balls)\n",
    "rbw = spark.sql('select t9.batsman as Batsman, nvl(t8.running_between_wickets,0) as Running_Between_Wickets from \\\n",
    "                (select t4.batsman, t4.first_bracket/t7.second_bracket as Running_Between_Wickets from \\\n",
    "                (select t1.batsman, t3.total_runs-(t1.fours*4 + t2.sixes*6) as first_bracket \\\n",
    "                from (select batsman,count(*) as fours from analysis_db where batsman_runs = 4 \\\n",
    "                group by batsman) t1 \\\n",
    "                inner join \\\n",
    "                (select batsman,count(*) as sixes from analysis_db where batsman_runs = 6 group by batsman) t2 \\\n",
    "                on t1.batsman=t2.batsman \\\n",
    "                inner join \\\n",
    "                (select batsman,sum(batsman_runs) as total_runs from analysis_db group by batsman) t3 \\\n",
    "                on t3.batsman=t1.batsman) t4 \\\n",
    "                inner join\\\n",
    "                (select t5.batsman, t5.total_balls_played-t6.boundry_balls as second_bracket from \\\n",
    "                (select batsman, count(*) as total_balls_played from analysis_db group by batsman) t5 \\\n",
    "                inner join \\\n",
    "                (select batsman, count(*) as boundry_balls from analysis_db where batsman_runs=4 or batsman_runs=6 group by batsman) t6\\\n",
    "                on t5.batsman=t6.batsman) t7 \\\n",
    "                on t4.batsman=t7.batsman) t8 \\\n",
    "                right join \\\n",
    "                no_of_matches_table t9 \\\n",
    "                on t8.batsman = t9.batsman')\n",
    "rbw.registerTempTable('running_between_wickets_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------------------+\n",
      "|Rank|       Batsman|Running_Between_Wickets|\n",
      "+----+--------------+-----------------------+\n",
      "|   1|  Bipul Sharma|     0.8557692307692307|\n",
      "|   2|       TM Head|     0.8320610687022901|\n",
      "|   3|    WPUJC Vaas|     0.8088235294117647|\n",
      "|   4|     V Shankar|     0.7924528301886793|\n",
      "|   5|      M Kartik|     0.7821782178217822|\n",
      "|   6| Mohammad Nabi|     0.7792207792207793|\n",
      "|   7|     BA Stokes|     0.7647058823529411|\n",
      "|   8|A Ashish Reddy|     0.7636363636363637|\n",
      "|   8|     CH Morris|     0.7636363636363637|\n",
      "|  10|        S Gill|     0.7623456790123457|\n",
      "+----+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbw = spark.sql('select rank() over (order by running_between_wickets desc) as Rank, t1.* \\\n",
    "                  from running_between_wickets_table t1 \\\n",
    "                  inner join \\\n",
    "                  no_of_matches_table t2\\\n",
    "                  on t1.batsman = t2.batsman where no_of_matches>9')\n",
    "rbw.registerTempTable('running_between_wickets_rank')\n",
    "rbw.show(10)\n",
    "c = spark.sql('select count(*) from running_between_wickets_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------------------+------------------+\n",
      "|Rank|       Batsman|Running_Between_Wickets|            Points|\n",
      "+----+--------------+-----------------------+------------------+\n",
      "|   1|  Bipul Sharma|     0.8557692307692307|0.9958333333333333|\n",
      "|   2|       TM Head|     0.8320610687022901|0.9916666666666667|\n",
      "|   3|    WPUJC Vaas|     0.8088235294117647|            0.9875|\n",
      "|   4|     V Shankar|     0.7924528301886793|0.9833333333333333|\n",
      "|   5|      M Kartik|     0.7821782178217822|0.9791666666666666|\n",
      "|   6| Mohammad Nabi|     0.7792207792207793|             0.975|\n",
      "|   7|     BA Stokes|     0.7647058823529411|0.9708333333333333|\n",
      "|   8|A Ashish Reddy|     0.7636363636363637|0.9666666666666667|\n",
      "|   8|     CH Morris|     0.7636363636363637|0.9666666666666667|\n",
      "|  10|        S Gill|     0.7623456790123457|0.9583333333333334|\n",
      "+----+--------------+-----------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbw = spark.sql('select t1.*, (240-rank)/240 as Points from running_between_wickets_rank t1')\n",
    "rbw.registerTempTable('running_between_wickets_points')\n",
    "rbw.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------------------+------------------+------------------+\n",
      "|Rank|       Batsman|Running_Between_Wickets|            Points|            weight|\n",
      "+----+--------------+-----------------------+------------------+------------------+\n",
      "|   1|  Bipul Sharma|     0.8557692307692307|0.9958333333333333|0.9958333333333333|\n",
      "|   2|       TM Head|     0.8320610687022901|0.9916666666666667|0.9916666666666667|\n",
      "|   3|    WPUJC Vaas|     0.8088235294117647|            0.9875|            0.9875|\n",
      "|   4|     V Shankar|     0.7924528301886793|0.9833333333333333|0.9833333333333333|\n",
      "|   5|      M Kartik|     0.7821782178217822|0.9791666666666666|0.9791666666666666|\n",
      "|   6| Mohammad Nabi|     0.7792207792207793|             0.975|             0.975|\n",
      "|   7|     BA Stokes|     0.7647058823529411|0.9708333333333333|0.9708333333333333|\n",
      "|   8|A Ashish Reddy|     0.7636363636363637|0.9666666666666667|0.9666666666666667|\n",
      "|   8|     CH Morris|     0.7636363636363637|0.9666666666666667|0.9666666666666667|\n",
      "|  10|        S Gill|     0.7623456790123457|0.9583333333333334|0.9583333333333334|\n",
      "+----+--------------+-----------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbw = spark.sql('select t1.*, Points as weight from running_between_wickets_points t1')\n",
    "rbw.registerTempTable('running_between_wickets_weights')\n",
    "rbw.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bowling Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Economy = Runs Scored/(Number of balls bowled by bowler/6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wicket Taking Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wicket Taking Ability = Number of balls bowled / Wickets Taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency = Runs Conceded / Wickets Taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crucial Wicket Taking Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crucial Wicket Taking Ability = Number of times Four or Five Wickets Taken / Number of Innings Played\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Performance Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short Performance Index = (Wickets Taken – 4* Number of Times Four Wickets Taken – 5* Number of Times Five Wickets Taken) / (Innings Played – Number of Times Four Wickets or Five Wickets Taken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
